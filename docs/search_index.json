[["index.html", "Data Science Toolbook Contents Variable Types and Symbols", " Data Science Toolbook Heather Song Contents Variable Types and Symbols \\[ \\begin{align} input \\ vector: X_j &amp; = \\begin{bmatrix} x_{j,1}\\\\x_{j,2}\\\\ ..\\\\ x_{j,p} \\\\ \\end{bmatrix}\\\\ input \\ matrix: X_{n\\times p} &amp;= \\begin{bmatrix} x_{1,1},x_{1,2},......x_{1,p} \\\\ x_{2,1},x_{2,2},......x_{2,p} \\\\ .................. \\\\ x_{n,1},x_{n,2},......x_{n,p} \\end{bmatrix}\\\\ &amp;=\\begin{bmatrix} X_1^T\\\\ X_2^T\\\\ .\\\\ .\\\\ X_n^T \\end{bmatrix}\\\\ estimation &amp;=\\hat Y \\end{align} \\] "],["machine-learning.html", "Chapter 1 Machine Learning 1.1 Least Square 1.2 Nearest Neighbor", " Chapter 1 Machine Learning 1.1 Least Square Least Square is most simple method for quantative prediction, which makes huge assumptions about structure and yields stable but possibly inaccurate predictions. Basic functions are as follows: \\(X\\) is a \\(1\\times n\\) column vector and \\(\\hat Y\\) is a single output: \\[ \\begin{align} Input: vector \\ X^T &amp;= (X_1, X_2,......, X_p) \\\\ Prediction: scalar\\ \\hat Y &amp;= \\hat \\beta_0+\\sum_{j=1}^p X_j \\hat \\beta_j \\end{align} \\] \\(X\\) is a \\(n\\times p\\) column vector and \\(\\hat Y\\) is a \\(n\\times 1\\) column vector: $$ \\[\\begin{align} input \\ matrix: X_{n\\times p} &amp;= \\begin{bmatrix} X_1, X_2,......, X_p \\end{bmatrix}\\\\ &amp;=\\begin{bmatrix} ...... ,x_{1j} ,......\\\\ ......, x_{2j}, ......\\\\ ......,x_{3j} ,......\\\\ .................\\\\ ......,x_{nj}, ...... \\end{bmatrix}\\\\ Prediction: \\hat Y_{n\\times 1} &amp;= \\hat \\beta_0+\\sum_{j=1}^p X_j \\hat \\beta_j\\\\ &amp;= \\hat \\beta_0 + \\begin{bmatrix} x_{11}\\\\ x_{21}\\\\ x_{31}\\\\ ..\\\\ x_{n1}\\end{bmatrix}\\hat \\beta_1+... + \\begin{bmatrix} x_{1j}\\\\ x_{2j}\\\\ x_{3j}\\\\ ..\\\\ x_{nj}\\end{bmatrix}\\hat \\beta_j+... + \\begin{bmatrix} x_{1p}\\\\ x_{2p}\\\\ x_{3p}\\\\ ..\\\\ x_{np}\\end{bmatrix}\\hat \\beta_p\\\\ bias \\ \\hat \\beta_0 : n\\times 1 \\\\ X_j : n\\times 1 \\end{align}\\] $$ \\(X\\) is a \\(n\\times p\\) column vector and \\(\\hat Y\\) is a \\(n\\times K\\) matrix: 1.2 Nearest Neighbor Some Markdown text with some blue text. "],["data-transformation.html", "Chapter 2 Data transformation", " Chapter 2 Data transformation "],["missing-values.html", "Chapter 3 Missing values", " Chapter 3 Missing values "],["results.html", "Chapter 4 Results", " Chapter 4 Results "],["interactive-component.html", "Chapter 5 Interactive component", " Chapter 5 Interactive component "],["conclusion.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion "]]
